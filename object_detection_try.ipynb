{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pyimagesearch.com/2020/06/22/turning-any-cnn-image-classifier-into-an-object-detector-with-keras-tensorflow-and-opencv/#pyis-cta-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FÃ¼r Colab\n",
    "!git clone -b master https://github.com/HennFarr/Coins.git\n",
    "!pip install keras_tuner\n",
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "import keras_tuner as kt\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array,load_img\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import shap\n",
    "\n",
    "import imutils\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_dir = \"Models/Tuned/tuned_model\"\n",
    "colab_model_dir = \"/content/Coins/Models/Tuned/tuned_model\"\n",
    "model = keras.models.load_model(local_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step, ws):\n",
    "\t# slide a window across the image\n",
    "\tfor y in range(0, image.shape[0] - ws[1], step):\n",
    "\t\tfor x in range(0, image.shape[1] - ws[0], step):\n",
    "\t\t\t# yield the current window\n",
    "\t\t\tyield (x, y, image[y:y + ws[1], x:x + ws[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pyramid(image, scale=1.5, minSize=(200, 200)):\n",
    "\t# yield the original image\n",
    "\tyield image\n",
    "\t# keep looping over the image pyramid\n",
    "\twhile True:\n",
    "\t\t# compute the dimensions of the next image in the pyramid\n",
    "\t\tw = int(image.shape[1] / scale)\n",
    "\t\timage = imutils.resize(image, width=w)\n",
    "\t\t# if the resized image does not meet the supplied minimum\n",
    "\t\t# size, then stop constructing the pyramid\n",
    "\t\tif image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "\t\t\tbreak\n",
    "\t\t# yield the next image in the pyramid\n",
    "\t\tyield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables used for the object detection procedure\n",
    "WIDTH = 1200\n",
    "PYR_SCALE = 0.5 \n",
    "WIN_STEP = 8\n",
    "ROI_SIZE = (100,100) #eval(args[\"size\"])\n",
    "INPUT_SIZE = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img=\"real_test_data/multi/IMG_20220620_105307.jpg\"\n",
    "colab_img=\"/content/Coins/real_test_data/multi/IMG_20220620_105307.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image from disk, resize it such that it has the\n",
    "# has the supplied width, and then grab its dimensions\n",
    "orig = cv2.imread(colab_img) #args[\"image\"]\n",
    "orig = imutils.resize(orig, width=WIDTH)\n",
    "(H, W) = orig.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the image pyramid\n",
    "pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n",
    "# initialize two lists, one to hold the ROIs generated from the image\n",
    "# pyramid and sliding window, and another list used to store the\n",
    "# (x, y)-coordinates of where the ROI was in the original image\n",
    "rois = []\n",
    "locs = []\n",
    "# time how long it takes to loop over the image pyramid layers and\n",
    "# sliding window locations\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the image pyramid\n",
    "for image in pyramid:\n",
    "\t# determine the scale factor between the *original* image\n",
    "\t# dimensions and the *current* layer of the pyramid\n",
    "\tscale = W / float(image.shape[1])\n",
    "\t# for each layer of the image pyramid, loop over the sliding\n",
    "\t# window locations\n",
    "\tfor (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n",
    "\t\t# scale the (x, y)-coordinates of the ROI with respect to the\n",
    "\t\t# *original* image dimensions\n",
    "\t\tx = int(x * scale)\n",
    "\t\ty = int(y * scale)\n",
    "\t\tw = int(ROI_SIZE[0] * scale)\n",
    "\t\th = int(ROI_SIZE[1] * scale)\n",
    "\t\t# take the ROI and preprocess it so we can later classify\n",
    "\t\t# the region using Keras/TensorFlow\n",
    "\t\troi = cv2.resize(roiOrig, INPUT_SIZE)\n",
    "\t\troi = img_to_array(roi)\n",
    "\t\troi = preprocess_input(roi)\n",
    "\t\t# update our list of ROIs and associated coordinates\n",
    "\t\trois.append(roi)\n",
    "\t\tlocs.append((x, y, x + w, y + h))\n",
    "\t\t# check to see if we are visualizing each of the sliding\n",
    "\t\t# windows in the image pyramid\n",
    "\t\tif 0 > 0:\t\t\t#args[\"visualize\"] # Dauert ewig\n",
    "\t\t\t# clone the original image and then draw a bounding box\n",
    "\t\t\t# surrounding the current region\n",
    "\t\t\tclone = orig.copy()\n",
    "\t\t\tcv2.rectangle(clone, (x, y), (x + w, y + h),\n",
    "\t\t\t\t(0, 255, 0), 2)\n",
    "\t\t\t# show the visualization and current ROI\n",
    "\t\t\tcv2.imshow(\"Visualization\", clone)\n",
    "\t\t\tcv2.imshow(\"ROI\", roiOrig)\n",
    "\t\t\tcv2.waitKey(0)\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] looping over pyramid/windows took 1.07703 seconds\n",
      "[INFO] classifying ROIs...\n",
      "[INFO] classifying ROIs took 51.35710 seconds\n"
     ]
    }
   ],
   "source": [
    "# show how long it took to loop over the image pyramid layers and\n",
    "# sliding window locations\n",
    "end = time.time()\n",
    "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n",
    "\tend - start))\n",
    "# convert the ROIs to a NumPy array\n",
    "rois = np.array(rois, dtype=\"float32\")\n",
    "# classify each of the proposal ROIs using ResNet and then show how\n",
    "# long the classifications took\n",
    "print(\"[INFO] classifying ROIs...\")\n",
    "start = time.time()\n",
    "preds = model.predict(rois)\n",
    "end = time.time()\n",
    "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
    "\tend - start))\n",
    "# decode the predictions and initialize a dictionary which maps class\n",
    "# labels (keys) to any ROIs associated with that label (values)\n",
    "#preds = np.argmax(preds)\n",
    "labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=[\"1c\", \"2c\", \"5c\", \"10c\", \"20c\", \"50c\", \"1e\", \"2e\"]\n",
    "preds2=[]\n",
    "for i in preds:\n",
    "    preds2.append([np.argmax(i), class_names[np.argmax(i)],list(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, '1c', [0.7914876, 0.006152154, 0.2023602, 1.1815348e-12, 1.6282584e-14, 7.3005356e-14, 1.474599e-14, 1.8731859e-13]], [0, '1c', [0.7777554, 0.0063336375, 0.21591103, 1.0093326e-13, 1.9836751e-15, 9.534898e-15, 2.6914533e-15, 3.0778795e-14]], [0, '1c', [0.8141323, 0.005382456, 0.1804853, 1.1250052e-14, 2.6741238e-16, 1.3100334e-15, 5.2248465e-16, 5.8083866e-15]], [0, '1c', [0.84113246, 0.0038004648, 0.15506709, 8.434334e-15, 1.4571039e-16, 6.8611956e-16, 1.7860918e-16, 3.0756198e-15]], [0, '1c', [0.8206807, 0.002853122, 0.17646624, 1.9266889e-15, 3.16053e-17, 1.8393001e-16, 4.553212e-17, 8.246002e-16]], [0, '1c', [0.82748675, 0.00280274, 0.16971049, 2.309757e-15, 2.4739152e-17, 1.2477797e-16, 2.8411444e-17, 5.8534964e-16]], [0, '1c', [0.8088551, 0.003103855, 0.18804103, 2.8528233e-15, 2.7231671e-17, 1.337458e-16, 3.7622414e-17, 5.131168e-16]], [0, '1c', [0.7930388, 0.0024289524, 0.20453227, 5.9214447e-15, 4.1940946e-17, 1.8320135e-16, 5.5155364e-17, 7.7447007e-16]], [0, '1c', [0.78742546, 0.0031469318, 0.20942764, 2.4105917e-14, 1.7045322e-16, 7.719243e-16, 2.1790574e-16, 2.438708e-15]], [0, '1c', [0.7360447, 0.0035275314, 0.2604278, 5.7480685e-15, 7.2722775e-17, 4.461936e-16, 1.5484112e-16, 1.4690019e-15]], [0, '1c', [0.6690948, 0.0017092297, 0.32919604, 9.18148e-16, 1.1571278e-17, 7.9493314e-17, 1.9144007e-17, 2.3789696e-16]], [0, '1c', [0.72501165, 0.0024746282, 0.2725138, 2.4941215e-15, 2.0625138e-17, 1.306182e-16, 3.0928118e-17, 6.293606e-16]], [0, '1c', [0.61709446, 0.0020577062, 0.38084787, 3.728346e-16, 5.2130295e-18, 5.0738322e-17, 9.920178e-18, 1.1763265e-16]], [0, '1c', [0.62544554, 0.0015650728, 0.3729894, 5.5154094e-17, 1.0125474e-18, 1.2865108e-17, 2.1635256e-18, 3.2769342e-17]], [0, '1c', [0.63345534, 0.0015454611, 0.3649992, 8.9216366e-17, 1.8837365e-18, 2.5519217e-17, 2.6300059e-18, 5.3604377e-17]], [0, '1c', [0.63772804, 0.0015062018, 0.36076576, 6.823496e-17, 1.2714834e-18, 1.9147547e-17, 2.1069765e-18, 3.777547e-17]], [0, '1c', [0.6682144, 0.0013725867, 0.330413, 3.9877143e-17, 8.059023e-19, 9.9315465e-18, 1.2811251e-18, 2.0183177e-17]], [0, '1c', [0.75099593, 0.00138725, 0.24761674, 8.4980863e-17, 1.4984906e-18, 1.3072369e-17, 1.6686735e-18, 3.8003328e-17]], [0, '1c', [0.73700756, 0.0020135161, 0.26097894, 5.559194e-16, 8.741295e-18, 7.584497e-17, 7.958281e-18, 1.8222602e-16]], [0, '1c', [0.70048463, 0.0010103349, 0.29850513, 3.0422876e-17, 7.4561823e-19, 9.4168044e-18, 1.2255567e-18, 2.053127e-17]]]\n"
     ]
    }
   ],
   "source": [
    "print(preds2[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the predictions\n",
    "for (i,p) in enumerate(preds2):\n",
    "\t# grab the prediction information for the current ROI\n",
    "\t(coinID, label, prob) = p\n",
    "\t# filter out weak detections by ensuring the predicted probability\n",
    "\t# is greater than the minimum probability\n",
    "\tif prob[coinID] >= 0.9:\t#args[\"min_conf\"]\n",
    "\t\t# grab the bounding box associated with the prediction and\n",
    "\t\t# convert the coordinates\n",
    "\t\tbox = locs[i]\n",
    "\t\t# grab the list of predictions for the label and add the\n",
    "\t\t# bounding box and probability to the list\n",
    "\t\tL = labels.get(label, [])\n",
    "\t\tL.append((box, prob[coinID]))\n",
    "\t\tlabels[label] = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] showing results for '1c'\n",
      "[INFO] showing results for '2c'\n",
      "[INFO] showing results for '10c'\n",
      "[INFO] showing results for '1e'\n",
      "[INFO] showing results for '2e'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# loop over the labels for each of detected objects in the image\n",
    "for label in labels.keys():\n",
    "\t# clone the original image so that we can draw on it\n",
    "\tprint(\"[INFO] showing results for '{}'\".format(label))\n",
    "\tclone = orig.copy()\n",
    "\t# loop over all bounding boxes for the current label\n",
    "\tfor (box, prob) in labels[label]:\n",
    "\t\t# draw the bounding box on the image\n",
    "\t\t(startX, startY, endX, endY) = box\n",
    "\t\tcv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "\t\t\t(0, 255, 0), 2)\n",
    "\t# show the results *before* applying non-maxima suppression, then\n",
    "\t# clone the image again so we can display the results *after*\n",
    "\t# applying non-maxima suppression\n",
    "\tcv2.imshow(\"Before\", clone)\n",
    "\tclone = orig.copy()\n",
    "    # extract the bounding boxes and associated prediction\n",
    "\t# probabilities, then apply non-maxima suppression\n",
    "\tboxes = np.array([p[0] for p in labels[label]])\n",
    "\tproba = np.array([p[1] for p in labels[label]])\n",
    "\tboxes = non_max_suppression(boxes, proba)\n",
    "\t# loop over all bounding boxes that were kept after applying\n",
    "\t# non-maxima suppression\n",
    "\tfor (startX, startY, endX, endY) in boxes:\n",
    "\t\t# draw the bounding box and label on the image\n",
    "\t\tcv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "\t\t\t(0, 255, 0), 2)\n",
    "\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\t\tcv2.putText(clone, label, (startX, y),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "\t# show the output after apply non-maxima suppression\n",
    "\tcv2.imshow(\"After\", clone)\n",
    "\tcv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "693d33b25e137953b2d4b36c13a5352a3d9041db4a0407afc24fded26f75a3a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

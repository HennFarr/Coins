{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pyimagesearch.com/2020/06/22/turning-any-cnn-image-classifier-into-an-object-detector-with-keras-tensorflow-and-opencv/#pyis-cta-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FÃ¼r Colab\n",
    "#!git clone -b master https://github.com/HennFarr/Coins.git\n",
    "#!pip install keras_tuner\n",
    "#!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from keras import layers\n",
    "import keras_tuner as kt\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array,load_img\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import os\n",
    "import shap\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_dir = \"Models/Tuned/tuned_model\"\n",
    "colab_model_dir = \"/content/Coins/Models/Tuned/tuned_model\"\n",
    "model2 = keras.models.load_model(local_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading network...\")\n",
    "model = ResNet50(weights=\"imagenet\", include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step, ws):\n",
    "\t# slide a window across the image\n",
    "\tfor y in range(0, image.shape[0] - ws[1], step):\n",
    "\t\tfor x in range(0, image.shape[1] - ws[0], step):\n",
    "\t\t\t# yield the current window\n",
    "\t\t\tyield (x, y, image[y:y + ws[1], x:x + ws[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pyramid(image, scale, minSize):\n",
    "\t# yield the original image\n",
    "\tyield image\n",
    "\t# keep looping over the image pyramid\n",
    "\twhile True:\n",
    "\t\t# compute the dimensions of the next image in the pyramid\n",
    "\t\tw = int(image.shape[1] / scale)\n",
    "\t\timage = imutils.resize(image, width=w)\n",
    "\t\t# if the resized image does not meet the supplied minimum\n",
    "\t\t# size, then stop constructing the pyramid\n",
    "\t\tif image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "\t\t\tbreak\n",
    "\t\t# yield the next image in the pyramid\n",
    "\t\tyield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables used for the object detection procedure\n",
    "WIDTH = 600\n",
    "PYR_SCALE = 1.5\n",
    "WIN_STEP = 16\n",
    "ROI_SIZE = (80,80) #eval(args[\"size\"])\n",
    "INPUT_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_img=\"real_test_data/multi/IMG_20220620_105307.jpg\"\n",
    "colab_img=\"/content/Coins/real_test_data/multi/IMG_20220620_105307.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image from disk, resize it such that it has the\n",
    "# has the supplied width, and then grab its dimensions\n",
    "orig = cv2.imread(local_img) #args[\"image\"]\n",
    "orig = imutils.resize(orig, width=WIDTH)\n",
    "(H, W) = orig.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the image pyramid\n",
    "pyramid = image_pyramid(orig, scale=PYR_SCALE, minSize=ROI_SIZE)\n",
    "# initialize two lists, one to hold the ROIs generated from the image\n",
    "# pyramid and sliding window, and another list used to store the\n",
    "# (x, y)-coordinates of where the ROI was in the original image\n",
    "rois = []\n",
    "locs = []\n",
    "# time how long it takes to loop over the image pyramid layers and\n",
    "# sliding window locations\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the image pyramid\n",
    "for image in pyramid:\n",
    "\t# determine the scale factor between the *original* image\n",
    "\t# dimensions and the *current* layer of the pyramid\n",
    "\tscale = W / float(image.shape[1])\n",
    "\t# for each layer of the image pyramid, loop over the sliding\n",
    "\t# window locations\n",
    "\tfor (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):\n",
    "\t\t# scale the (x, y)-coordinates of the ROI with respect to the\n",
    "\t\t# *original* image dimensions\n",
    "\t\tx = int(x * scale)\n",
    "\t\ty = int(y * scale)\n",
    "\t\tw = int(ROI_SIZE[0] * scale)\n",
    "\t\th = int(ROI_SIZE[1] * scale)\n",
    "\t\t# take the ROI and preprocess it so we can later classify\n",
    "\t\t# the region using Keras/TensorFlow\n",
    "\t\troi = cv2.resize(roiOrig, INPUT_SIZE)\n",
    "\t\troi = img_to_array(roi)\n",
    "\t\troi = preprocess_input(roi)\n",
    "\t\t# update our list of ROIs and associated coordinates\n",
    "\t\trois.append(roi)\n",
    "\t\tlocs.append((x, y, x + w, y + h))\n",
    "\t\t# check to see if we are visualizing each of the sliding\n",
    "\t\t# windows in the image pyramid\n",
    "\t\tif 0 > 0:\t\t\t#args[\"visualize\"] # Dauert ewig\n",
    "\t\t\t# clone the original image and then draw a bounding box\n",
    "\t\t\t# surrounding the current region\n",
    "\t\t\tclone = orig.copy()\n",
    "\t\t\tcv2.rectangle(clone, (x, y), (x + w, y + h),\n",
    "\t\t\t\t(0, 255, 0), 2)\n",
    "\t\t\t# show the visualization and current ROI\n",
    "\t\t\tcv2.imshow(\"Visualization\", clone)\n",
    "\t\t\tcv2.imshow(\"ROI\", roiOrig)\n",
    "\t\t\tcv2.waitKey(0)\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] looping over pyramid/windows took 2.35129 seconds\n",
      "[INFO] classifying ROIs...\n",
      "[INFO] classifying ROIs took 161.79790 seconds\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "40960/35363 [==================================] - 0s 1us/step\n",
      "49152/35363 [=========================================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# show how long it took to loop over the image pyramid layers and\n",
    "# sliding window locations\n",
    "end = time.time()\n",
    "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(\n",
    "\tend - start))\n",
    "# convert the ROIs to a NumPy array\n",
    "rois = np.array(rois, dtype=\"float32\")\n",
    "# classify each of the proposal ROIs using ResNet and then show how\n",
    "# long the classifications took\n",
    "print(\"[INFO] classifying ROIs...\")\n",
    "start = time.time()\n",
    "preds = model.predict(rois)\n",
    "end = time.time()\n",
    "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(\n",
    "\tend - start))\n",
    "# decode the predictions and initialize a dictionary which maps class\n",
    "# labels (keys) to any ROIs associated with that label (values)\n",
    "preds = imagenet_utils.decode_predictions(preds, top=1)\n",
    "labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names=[\"1c\", \"2c\", \"5c\", \"10c\", \"20c\", \"50c\", \"1e\", \"2e\"]\n",
    "#preds2=[]\n",
    "#for i in preds:\n",
    "#    preds2.append([np.argmax(i), class_names[np.argmax(i)],list(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n01930112', 'nematode', 0.15131089)],\n",
       " [('n01930112', 'nematode', 0.2237454)],\n",
       " [('n01930112', 'nematode', 0.14520773)],\n",
       " [('n01930112', 'nematode', 0.12038318)],\n",
       " [('n01930112', 'nematode', 0.16201486)],\n",
       " [('n01930112', 'nematode', 0.13768193)],\n",
       " [('n01930112', 'nematode', 0.182246)],\n",
       " [('n01930112', 'nematode', 0.28152767)],\n",
       " [('n01930112', 'nematode', 0.38485435)],\n",
       " [('n01930112', 'nematode', 0.32143235)],\n",
       " [('n01930112', 'nematode', 0.28310326)],\n",
       " [('n01930112', 'nematode', 0.2834977)],\n",
       " [('n01930112', 'nematode', 0.25677288)],\n",
       " [('n01930112', 'nematode', 0.17542067)],\n",
       " [('n01930112', 'nematode', 0.15540104)],\n",
       " [('n01930112', 'nematode', 0.18794487)],\n",
       " [('n01930112', 'nematode', 0.20394059)],\n",
       " [('n01930112', 'nematode', 0.32338598)],\n",
       " [('n01930112', 'nematode', 0.3336396)],\n",
       " [('n01930112', 'nematode', 0.37153247)]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the predictions\n",
    "for (i, p) in enumerate(preds):\n",
    "\t# grab the prediction information for the current ROI\n",
    "\t(imagenetID, label, prob) = p[0]\n",
    "\t# filter out weak detections by ensuring the predicted probability\n",
    "\t# is greater than the minimum probability\n",
    "\tif prob >= 0.9:\n",
    "\t\t# grab the bounding box associated with the prediction and\n",
    "\t\t# convert the coordinates\n",
    "\t\tbox = locs[i]\n",
    "\t\t# grab the list of predictions for the label and add the\n",
    "\t\t# bounding box and probability to the list\n",
    "\t\tL = labels.get(label, [])\n",
    "\t\tL.append((box, prob))\n",
    "\t\tlabels[label] = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pick': [((80, 112, 160, 192), 0.92296326),\n",
       "  ((96, 112, 176, 192), 0.9310907),\n",
       "  ((64, 128, 144, 208), 0.98751926),\n",
       "  ((80, 128, 160, 208), 0.9496747),\n",
       "  ((96, 128, 176, 208), 0.97950625),\n",
       "  ((112, 128, 192, 208), 0.9836843),\n",
       "  ((64, 144, 144, 224), 0.95469904),\n",
       "  ((80, 144, 160, 224), 0.9644556),\n",
       "  ((96, 144, 176, 224), 0.9453947),\n",
       "  ((128, 144, 208, 224), 0.9128385),\n",
       "  ((496, 192, 576, 272), 0.9592259),\n",
       "  ((496, 208, 576, 288), 0.9180829),\n",
       "  ((320, 224, 400, 304), 0.9205445),\n",
       "  ((320, 272, 400, 352), 0.9453659),\n",
       "  ((368, 272, 448, 352), 0.9350854),\n",
       "  ((48, 336, 128, 416), 0.9615812),\n",
       "  ((400, 352, 480, 432), 0.9478555),\n",
       "  ((144, 400, 224, 480), 0.9377926),\n",
       "  ((208, 400, 288, 480), 0.9014451),\n",
       "  ((48, 448, 128, 528), 0.9615007),\n",
       "  ((48, 464, 128, 544), 0.9388951),\n",
       "  ((48, 480, 128, 560), 0.9278976),\n",
       "  ((304, 560, 384, 640), 0.92543167),\n",
       "  ((304, 576, 384, 656), 0.9187686),\n",
       "  ((320, 576, 400, 656), 0.9068292),\n",
       "  ((96, 640, 176, 720), 0.9034279),\n",
       "  ((96, 72, 216, 192), 0.9308994),\n",
       "  ((72, 96, 192, 216), 0.92226976),\n",
       "  ((144, 96, 264, 216), 0.95737624),\n",
       "  ((192, 120, 312, 240), 0.92169833),\n",
       "  ((192, 144, 312, 264), 0.9173907),\n",
       "  ((192, 168, 312, 288), 0.9253501),\n",
       "  ((264, 264, 384, 384), 0.9451741),\n",
       "  ((312, 264, 432, 384), 0.9080024),\n",
       "  ((336, 264, 456, 384), 0.99116),\n",
       "  ((336, 288, 456, 408), 0.9303137),\n",
       "  ((360, 288, 480, 408), 0.9519047),\n",
       "  ((384, 288, 504, 408), 0.98306686),\n",
       "  ((336, 312, 456, 432), 0.9458037),\n",
       "  ((360, 312, 480, 432), 0.9647726),\n",
       "  ((0, 336, 120, 456), 0.96984214),\n",
       "  ((336, 336, 456, 456), 0.9303557),\n",
       "  ((144, 360, 264, 480), 0.9008679),\n",
       "  ((144, 384, 264, 504), 0.963126),\n",
       "  ((144, 456, 264, 576), 0.931799),\n",
       "  ((72, 600, 192, 720), 0.9130167),\n",
       "  ((144, 36, 324, 216), 0.9119142),\n",
       "  ((252, 36, 432, 216), 0.9303421),\n",
       "  ((360, 36, 540, 216), 0.9187939),\n",
       "  ((144, 72, 324, 252), 0.9950276),\n",
       "  ((180, 72, 360, 252), 0.9431339),\n",
       "  ((252, 72, 432, 252), 0.9647486),\n",
       "  ((144, 108, 324, 288), 0.9927247),\n",
       "  ((0, 433, 180, 613), 0.93125373)],\n",
       " 'Petri_dish': [((384, 112, 464, 192), 0.9356153),\n",
       "  ((336, 160, 416, 240), 0.95510674),\n",
       "  ((352, 160, 432, 240), 0.92823803),\n",
       "  ((128, 176, 208, 256), 0.938064),\n",
       "  ((96, 192, 176, 272), 0.9149051),\n",
       "  ((112, 192, 192, 272), 0.9446046),\n",
       "  ((96, 208, 176, 288), 0.95525706),\n",
       "  ((64, 240, 144, 320), 0.95596474),\n",
       "  ((80, 240, 160, 320), 0.989407),\n",
       "  ((96, 240, 176, 320), 0.9931478),\n",
       "  ((96, 256, 176, 336), 0.91472906),\n",
       "  ((128, 336, 208, 416), 0.949151),\n",
       "  ((144, 336, 224, 416), 0.9372852),\n",
       "  ((128, 352, 208, 432), 0.935708),\n",
       "  ((144, 352, 224, 432), 0.916585),\n",
       "  ((176, 352, 256, 432), 0.94350684),\n",
       "  ((432, 352, 512, 432), 0.9094605),\n",
       "  ((448, 352, 528, 432), 0.9806286),\n",
       "  ((464, 352, 544, 432), 0.96604955),\n",
       "  ((112, 368, 192, 448), 0.95773923),\n",
       "  ((448, 368, 528, 448), 0.91666055),\n",
       "  ((96, 384, 176, 464), 0.9340855),\n",
       "  ((112, 384, 192, 464), 0.97934717),\n",
       "  ((448, 384, 528, 464), 0.9109242),\n",
       "  ((480, 384, 560, 464), 0.9440622),\n",
       "  ((80, 416, 160, 496), 0.90346485),\n",
       "  ((240, 480, 320, 560), 0.96636873),\n",
       "  ((256, 480, 336, 560), 0.9141997),\n",
       "  ((240, 496, 320, 576), 0.93978274),\n",
       "  ((256, 496, 336, 576), 0.93128103),\n",
       "  ((320, 496, 400, 576), 0.9094297),\n",
       "  ((304, 512, 384, 592), 0.97878075),\n",
       "  ((368, 512, 448, 592), 0.90063345),\n",
       "  ((304, 528, 384, 608), 0.9081523),\n",
       "  ((336, 96, 456, 216), 0.94965386),\n",
       "  ((336, 120, 456, 240), 0.92654485),\n",
       "  ((408, 120, 528, 240), 0.9176638),\n",
       "  ((48, 216, 168, 336), 0.93166476),\n",
       "  ((48, 240, 168, 360), 0.9094156),\n",
       "  ((144, 264, 264, 384), 0.97099036),\n",
       "  ((144, 288, 264, 408), 0.9694231),\n",
       "  ((96, 336, 216, 456), 0.96780056),\n",
       "  ((264, 504, 384, 624), 0.9704949),\n",
       "  ((324, 108, 504, 288), 0.95253164),\n",
       "  ((144, 216, 324, 396), 0.9755314),\n",
       "  ((252, 360, 432, 540), 0.9061883),\n",
       "  ((271, 108, 542, 379), 0.95334625),\n",
       "  ((54, 162, 325, 433), 0.93118966),\n",
       "  ((108, 162, 379, 433), 0.9597549),\n",
       "  ((162, 162, 433, 433), 0.9241853),\n",
       "  ((216, 162, 487, 433), 0.90366787),\n",
       "  ((271, 162, 542, 433), 0.91880655),\n",
       "  ((108, 216, 379, 487), 0.90895754),\n",
       "  ((108, 271, 379, 542), 0.933495),\n",
       "  ((54, 325, 325, 596), 0.9303628)],\n",
       " 'typewriter_keyboard': [((288, 336, 368, 416), 0.9016065)],\n",
       " 'combination_lock': [((224, 416, 304, 496), 0.9080753)],\n",
       " 'digital_clock': [((416, 672, 496, 752), 0.9031474),\n",
       "  ((432, 672, 512, 752), 0.90216637),\n",
       "  ((416, 688, 496, 768), 0.9414695),\n",
       "  ((416, 704, 496, 784), 0.97720474)],\n",
       " 'jellyfish': [((312, 384, 432, 504), 0.90369964),\n",
       "  ((325, 488, 596, 759), 0.9221694)],\n",
       " 'nipple': [((192, 408, 312, 528), 0.9301599),\n",
       "  ((168, 528, 288, 648), 0.94263744),\n",
       "  ((192, 528, 312, 648), 0.95435125),\n",
       "  ((216, 528, 336, 648), 0.9466586),\n",
       "  ((240, 528, 360, 648), 0.90146065)],\n",
       " 'analog_clock': [((408, 576, 528, 696), 0.95780975),\n",
       "  ((360, 672, 480, 792), 0.92188704)],\n",
       " 'remote_control': [((162, 54, 433, 325), 0.9091502)]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] showing results for 'pick'\n",
      "[INFO] showing results for 'Petri_dish'\n",
      "[INFO] showing results for 'typewriter_keyboard'\n",
      "[INFO] showing results for 'combination_lock'\n",
      "[INFO] showing results for 'digital_clock'\n",
      "[INFO] showing results for 'jellyfish'\n",
      "[INFO] showing results for 'nipple'\n",
      "[INFO] showing results for 'analog_clock'\n",
      "[INFO] showing results for 'remote_control'\n"
     ]
    }
   ],
   "source": [
    "# loop over the labels for each of detected objects in the image\n",
    "for label in labels.keys():\n",
    "\t# clone the original image so that we can draw on it\n",
    "\tprint(\"[INFO] showing results for '{}'\".format(label))\n",
    "\tclone = orig.copy()\n",
    "\t# loop over all bounding boxes for the current label\n",
    "\tfor (box, prob) in labels[label]:\n",
    "\t\t# draw the bounding box on the image\n",
    "\t\t(startX, startY, endX, endY) = box\n",
    "\t\tcv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "\t\t\t(0, 255, 0), 2)\n",
    "\t# show the results *before* applying non-maxima suppression, then\n",
    "\t# clone the image again so we can display the results *after*\n",
    "\t# applying non-maxima suppression\n",
    "\tcv2.imshow(\"Before\", clone)\n",
    "\tclone = orig.copy()\n",
    "    # extract the bounding boxes and associated prediction\n",
    "\t# probabilities, then apply non-maxima suppression\n",
    "\tboxes = np.array([p[0] for p in labels[label]])\n",
    "\tproba = np.array([p[1] for p in labels[label]])\n",
    "\tboxes = non_max_suppression(boxes, proba)\n",
    "\t# loop over all bounding boxes that were kept after applying\n",
    "\t# non-maxima suppression\n",
    "\tfor (startX, startY, endX, endY) in boxes:\n",
    "\t\t# draw the bounding box and label on the image\n",
    "\t\tcv2.rectangle(clone, (startX, startY), (endX, endY),\n",
    "\t\t\t(0, 255, 0), 2)\n",
    "\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\t\tcv2.putText(clone, label, (startX, y),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "\t# show the output after apply non-maxima suppression\n",
    "\tcv2.imshow(\"After\", clone)\n",
    "\tcv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "693d33b25e137953b2d4b36c13a5352a3d9041db4a0407afc24fded26f75a3a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
